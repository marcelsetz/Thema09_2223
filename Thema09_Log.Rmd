---
title: "Thema09_Log"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width = 12,fig.height = 5, warning = FALSE, message = FALSE)
options(warn = 0)
library(ggplot2, quietly = TRUE)
library(ggbiplot, quietly = TRUE)
library(gridExtra, quietly = TRUE)
library(kableExtra, quietly = TRUE)
library(dplyr, quietly = TRUE)
library(tidyr, quietly = TRUE)
library(readr, quietly = TRUE)
library(pander, quietly = TRUE)
```

install kableExtra
install knitr

Urinary biomarkers for pancreatic cancer

https://www.kaggle.com/johnjdavisiv/urinary-biomarkers-for-pancreatic-
cancer

Research question: Is it possible to detect pancreatic cancer using values of the urinary biomarkers?

How can values of urinary biomarkers detect pancreatic cancer?

# Introduction
Pancreatic ductal adenocarcinoma (PDAC) is one of the deadiest cancers. The chances of survival are increased when diagnosed in an early stage. However, PDAC shows symptoms when it already spread throughout the body. Most of the time, it's too late by then. There may be a way to detect PCAD in an early stage with a simple urine test, with the use of the following biomarkers: creatinine (Urinary biomarker of kidney function) LYVE1 (Urinary levels of Lymphatic vessel endothelial hyaluronan receptor 1, a protein that may play a role in tumor metastasis), REG1A and REG1B (Urinary levels of a protein that may be associated with pancreas regeneration.), and TFF1 (Urinary levels of Trefoil Factor 1, which may be related to regeneration and repair of the urinary tract)

the attributes in the data interesting for this research are the biomarker values mentioned before. There is also an attribute called diagnosis, in which the diagnosis of the sample is stated, where 1 means no PDAC, 2 means benign hepatobiliary disease (non cancerous, non harmful pancreatic condition), and 3 means that the sample has PDAC.

# EDA
## Codebook
```{r, }
myData <- read.csv("Data/Debernardi et al 2020 data.csv")

columns <- colnames(myData)
type <- c("character", "character", "character", "double", "character", "double", "logical", "logical", "double", "double", "double", "double", "double", "double")
unit <- c(NA, NA, NA, "years", "F/M", NA, NA, NA, "U/ml", "mg/ml", "ng/ml", "ng/ml", "ng/ml", "ng/ml")
descriptions = c("Unique string identifying each subject", "Cohort 1, previously used samples; Cohort 2, newly added samples", "BPTB: Barts Pancreas Tissue Bank, London, UK; ESP: Spanish National Cancer Research Centre, Madrid, Spain; LIV: Liverpool University, UK; UCL: University College London, UK", "Age in years", "M = male, F = female", "1 = control (no pancreatic disease), 2 = benign hepatobiliary disease (119 of which are chronic pancreatitis); 3 = Pancreatic ductal adenocarcinoma, i.e. pancreatic cancer", "For those with pancratic cancer, what stage was it? One of IA, IB, IIA, IIIB, III, IV", "For those with a benign, non-cancerous diagnosis, what was the diagnosis?", "Blood plasma levels of CA 19â€“9 monoclonal antibody that is often elevated in patients with pancreatic cancer. Only assessed in 350 patients (one goal of the study was to compare various CA 19-9 cutpoints from a blood sample to the model developed using urinary samples).", "Urinary biomarker of kidney function", "Urinary levels of Lymphatic vessel endothelial hyaluronan receptor 1, a protein that may play a role in tumor metastasis", "Urinary levels of a protein that may be associated with pancreas regeneration.", "Urinary levels of Trefoil Factor 1, which may be related to regeneration and repair of the urinary tract", "Urinary levels of a protein that may be associated with pancreas regeneration. Only assessed in 306 patients (one goal of the study was to assess REG1B vs REG1A)")
codebook <- data.frame(columns, type, unit, descriptions)
write.csv(codebook, "Codebook.csv", row.names = FALSE)
```
\newpage
```{r}
pander(codebook, booktabs = T, caption="The Codebook")
```


## Data exploration
### Visualization
To look at the data and any possible missing data, here's a table containing only the relevant columns for this research.
```{r}
relevant <- myData[c(4, 6, 9:14)]
pander(head(relevant, n=15), booktabs = T, caption = "Values of biomarkers and the diagnosis")
```
  
As is it obvious to see, the REG1A column contains a lot of missing values. The question is exactly how is this possible and what does it mean for the rest of the data? The first and most simple solution is that we don't need this column at all, since the REG1B is similar in function and containing all of the data. Another solution that's not very logical, is to use only the rows where there is a value in the REG1A column. The most logical solution in my opinion is to look at every column separately, and then remove the missing data. When the cleaned data then is plotted, it's possible to look at all the columns together and see if there is any correlation or trend to figure out.


knowing this, let's have a look at the important raw data with the use of boxplots. 
```{r}
p1 <- ggplot(myData, aes(x=age)) +
  geom_histogram(fill = "lightgrey", col = "black", binwidth = 1)

p2 <- ggplot(myData, aes(x=creatinine)) +
  geom_boxplot()
p3 <- ggplot(myData, aes(x=LYVE1)) +
  geom_boxplot()
p4 <- ggplot(myData, aes(x=REG1B)) +
  geom_boxplot()
p5 <- ggplot(myData, aes(x=TFF1)) +
  geom_boxplot()
p6 <- ggplot(myData, aes(x=REG1A)) +
  geom_boxplot()

grid.arrange(p1, p2, p3, p4, p5, p6, nrow = 3)
```

as you can see, there are also a lot of outliers which we need to check. We can normalize the data using a log transformation.

```{r}
log <- log(myData[9:14] +1)
myData[9:14] <- log
```


Before proceeding, it is quite helpful to look at the distribution of the diagnosis column, to see if they're evenly distributed or not.

```{r}
ggplot(myData, aes(x=diagnosis)) +
  geom_histogram(fill = "lightgrey", col = "black", binwidth = 1) +
  ggtitle("Distribution of the diagnosis")

```

What we should do now, is look at the values of those urinary levels with each diagnosis and see if there are any obvious differences.  
Let's start with the samples that do not have PDAC
```{r}
myData1 <- subset(myData, myData$diagnosis == 1)

p1 <- ggplot(myData1, aes(x=age)) +
  geom_histogram(fill = "lightgrey", col = "black", binwidth = 1) +
  ggtitle("Age distribution")

p2 <- ggplot(myData1, aes(x=creatinine)) +
  geom_boxplot() +
  ggtitle("Distribution of creatinine")
p3 <- ggplot(myData1, aes(x=LYVE1)) +
  geom_boxplot() +
  ggtitle("Distribution of LYVE1")
p4 <- ggplot(myData1, aes(x=REG1B)) +
  geom_boxplot() +
  ggtitle("Distribution of REG1B")
p5 <- ggplot(myData1, aes(x=TFF1)) +
  geom_boxplot() +
  ggtitle("Distribution of TFF1")
p6 <- ggplot(myData1, aes(x=REG1A)) +
  geom_boxplot() +
  ggtitle("Distribution of REG1A")

grid.arrange(p1, p2, p3, p4, p5, p6, nrow = 3)
```

Here are the values of the samples with non-cancerous pancreatic conditions.

```{r}
myData2 <- subset(myData, myData$diagnosis == 2)

p1 <- ggplot(myData2, aes(x=age)) +
  geom_histogram(fill = "lightgrey", col = "black", binwidth = 1) +
  ggtitle("Age distribution")

p2 <- ggplot(myData2, aes(x=creatinine)) +
  geom_boxplot() +
  ggtitle("Distribution of creatinine")
p3 <- ggplot(myData2, aes(x=LYVE1)) +
  geom_boxplot() +
  ggtitle("Distribution of LYVE1")
p4 <- ggplot(myData2, aes(x=REG1B)) +
  geom_boxplot() +
  ggtitle("Distribution of REG1B")
p5 <- ggplot(myData2, aes(x=TFF1)) +
  geom_boxplot() +
  ggtitle("Distribution of TFF1")
p6 <- ggplot(myData2, aes(x=REG1A)) +
  geom_boxplot() +
  ggtitle("Distribution of REG1A")

grid.arrange(p1, p2, p3, p4, p5, p6, nrow = 3)
```

And finally the samples that do have PDAC.

```{r}
myData3 <- subset(myData, myData$diagnosis == 3)

p1 <- ggplot(myData3, aes(x=age)) +
  geom_histogram(fill = "lightgrey", col = "black", binwidth = 1) +
  ggtitle("Age distribution")

p2 <- ggplot(myData3, aes(x=creatinine)) +
  geom_boxplot() +
  ggtitle("Distribution of creatinine")
p3 <- ggplot(myData3, aes(x=LYVE1)) +
  geom_boxplot() +
  ggtitle("Distribution of LYVE1")
p4 <- ggplot(myData3, aes(x=REG1B)) +
  geom_boxplot() +
  ggtitle("Distribution of REG1B")
p5 <- ggplot(myData3, aes(x=TFF1)) +
  geom_boxplot() +
  ggtitle("Distribution of TFF1")
p6 <- ggplot(myData3, aes(x=REG1A)) +
  geom_boxplot() +
  ggtitle("Distribution of REG1A")

grid.arrange(p1, p2, p3, p4, p5, p6, nrow = 3)
```

At first glance, there are notable differences but we can further investigate this in future steps of this research.

```{r}
write.csv(myData, "Data/DataCleaned.csv")
```

### Correlation
Now we can check if the different biomarkers correlate with each other in any way.

```{r}
p1 <- ggplot(myData, aes(x=creatinine, y=LYVE1)) +
  geom_point() +
  geom_smooth(method='lm', formula = y~x) +
  ggtitle("Creatinine vs LYVE1")
p2 <- ggplot(myData, aes(x=creatinine, y=REG1B)) +
  geom_point() +
  geom_smooth(method='lm', formula = y~x) +
  ggtitle("Creatinine vs REG1B")
p3 <- ggplot(myData, aes(x=creatinine, y=TFF1)) +
  geom_point() +
  geom_smooth(method='lm', formula = y~x) +
  ggtitle("Creatinine vs TFF1")
p4 <- ggplot(myData, aes(x=LYVE1, y=REG1B)) +
  geom_point() +
  geom_smooth(method='lm', formula = y~x) +
  ggtitle("LYVE1 vs REG1B")
p5 <- ggplot(myData, aes(x=LYVE1, y=TFF1)) +
  geom_point() +
  geom_smooth(method='lm', formula = y~x) +
  ggtitle("LYVE1 vs TFF1")
p6 <- ggplot(myData, aes(x=TFF1, y=REG1B)) +
  geom_point() +
  geom_smooth(method='lm', formula = y~x) +
  ggtitle("TFF1 vs REG1B")

grid.arrange(p1, p2, p3, p4, p5, p6, nrow=3)
```

In this visualization there is a bit of correlation visible



Now, let's prepare the data for machine learning.
The first step will be to remove the columns  that aren't really necessary and relevant to the research to make it more clear.
\newpage
```{r}
myData <- subset(myData, select = -c(patient_cohort, sample_origin, benign_sample_diagnosis))
pander(summary(myData), booktabs = T, caption = "Relevant data")
```

## Quality Metrics
There are 3 possible diagnoses in this data, those are 1: The patient has PDAC; 2: The patient has pancreatic condition, but not cancer; and 3, The patient doesn't have any form of pancreatic conditions or cancer. 

It is important to determine the positive and negative diagnoses here, to find the true positives and true negatives. This research is about whether the sample has pancreatic cancer or not. So positive in this case will be diagnosis 1, and negative both 2 and 3, since they're both non-cancerous.

False negatives is the least wanted with research like this, because in that case the patient has PDAC, but the test says the patient doesn't, so there won't be any further treatment, while the patient needs it. it's better to have someone classified as PDAC, while the sample doesn't have it, because in further research to really test the person on PDAC, the test will come out negative.

In the machine learning process it's important to have the lowest possible amount of false negatives, so the false negative rate (FNR) should be as low as possible. The FNR tells of all the truly positives, what rate is wrongly classified. In the Java wrapper later on, it is important to calculate the FNR to see if it is reasonably low. On the other hand it is important to have a high amount of true positives, so those patients get the right treatment in time. So the FNR must be as low as possible while the TPR must be as high as possible.

## Machine learning algorithms
The next step is to determine which ML algorithm gives the best results. First let's look at the baseline accuracy with ZeroR. Weka correctly classifies 35.25% of the instances with 10-fold cross-validation. Using the experimenter in weka, it is possible to see the performance of every algorithm really fast. The experimenter uses 10-fold cross-validation and repeats it 10 times. So in the data there are 100 rows per ML algorithm. The code below reads per algorithm and averages the 100 rows to get a highly accurate representation of the results. In the table below there is a summary of every used cost-sensitive classifier and the resulting quality metrics. Remember it is important that the TPR is as high as possible, while the FNR is as low as possible.

```{r}
ML_dataLoc <- "Data/Experiment.csv"
ML_data <- read.csv(ML_dataLoc)
ML_ZeroR <- ML_data[c(1:100),]
ML_OneR <- ML_data[c(101:200),]
ML_J48 <- ML_data[c(201:300),]
ML_IBK <- ML_data[c(301:400),]
ML_NaiveBayes <- ML_data[c(401:500),]
ML_SimpleLog <- ML_data[c(501:600),]
ML_SMO <- ML_data[c(601:700),]
ML_RandomForest <- ML_data[c(701:800),]
algos <- list(ML_ZeroR, ML_OneR, ML_J48, ML_IBK, ML_NaiveBayes, ML_SimpleLog, ML_SMO, ML_RandomForest)
avgs_pc <- list()
avgs_pi <- list()
avgs_tp <- list()
avgs_fp <- list()
avgs_tn <- list()
avgs_fn <- list()
avgs_pr <- list()
avgs_rc <- list()
avgs_roc <- list()

for (algo in algos) {
  percent_correct <- algo[3]
  avg <- lapply(percent_correct, mean)
  avgs_pc[[length(avgs_pc) + 1]] <- avg
}
for (algo in algos) {
  percent_incorrect <- algo[4]
  avg <- lapply(percent_incorrect, mean)
  avgs_pi[[length(avgs_pi) + 1]] <- avg
}
for (algo in algos) {
  TP <- algo[5]
  avg <- lapply(TP, mean)
  avgs_tp[[length(avgs_tp) + 1]] <- avg
}
for (algo in algos) {
  FP <- algo[6]
  avg <- lapply(FP, mean)
  avgs_fp[[length(avgs_fp) + 1]] <- avg
}
for (algo in algos) {
  TN <- algo[7]
  avg <- lapply(TN, mean)
  avgs_tn[[length(avgs_tn) + 1]] <- avg
}
for (algo in algos) {
  FN <- algo[8]
  avg <- lapply(FN, mean)
  avgs_fn[[length(avgs_fn) + 1]] <- avg
}
for (algo in algos) {
  precision <- algo[9]
  avg <- lapply(precision, mean)
  avgs_pr[[length(avgs_pr) + 1]] <- avg
}
for (algo in algos) {
  recall <- algo[10]
  avg <- lapply(recall, mean)
  avgs_rc[[length(avgs_rc) + 1]] <- avg
}
for (algo in algos) {
  roc_area <- algo[11]
  avg <- lapply(roc_area, mean)
  avgs_roc[[length(avgs_roc) + 1]] <- avg
}
avgs_df <- data.frame(row.names = c("ZeroR", "OneR", "J48", "IBK", "NaiveBayes", "SimpleLogistics", "SMO", "RandomForest"))

vec_pc <- unlist(avgs_pc)
vec_pi <- unlist(avgs_pi)
vec_tp <- unlist(avgs_tp)
vec_fp <- unlist(avgs_fp)
vec_tn <- unlist(avgs_tn)
vec_fn <- unlist(avgs_fn)
vec_pr <- unlist(avgs_pr)
vec_rc <- unlist(avgs_rc)
vec_roc <- unlist(avgs_roc)

avgs_df$percent_correct_avgs <- vec_pc
avgs_df$percent_incorrect_avgs <- vec_pi
avgs_df$TP_avgs <- vec_tp
avgs_df$FP_avgs <- vec_fp
avgs_df$TN_avgs <- vec_tn
avgs_df$FN_avgs <- vec_fn
avgs_df$precision_avgs <- vec_pr
avgs_df$recall_avgs <- vec_rc
avgs_df$ROC_Area_avgs <- vec_roc

pander(avgs_df, booktabs = T, caption = "Machine Learning Summary")
write.csv(avgs_df, file = "Data/derbernardi_summary.csv")
```

